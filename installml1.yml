- hosts: all
  tasks:
  - name: Update Ubuntu
    shell: |
      apt-get -y update 
      apt-get -y upgrade
    sudo: yes
  - name: Check if Java is installed
    stat:
      path: /usr/bin/java
    register: java_is_installed
  - name: Install Java Apt
    apt:
      name: "{{ packages }}"
    vars:
      packages:
      - openjdk-8-*
#  - name: Install Java 8
#    shell: |
#      apt-get -y install openjdk-8-*
#    sudo: yes
#    when: java_is_installed.stat.exists == False
  - name: Check Scala Installed
    shell: dpkg --status scala | grep 'install ok installed'
    register: scala_is_installed
    failed_when: no
    changed_when: no
  - name: Install Scala
    shell: |
      wget -P /tmp http://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.deb
      dpkg -i /tmp/scala-2.11.8.deb
    when: scala_is_installed.rc == 1
    sudo: yes
  - name: Check if mvn is installed
    stat:
      path: /usr/local/apache-maven-3.6.3/bin/mvn
    register: mvn_is_installed
  - name: Install Maven
    shell: |
      wget -P /tmp http://www-us.apache.org/dist/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
      tar -zxf /tmp/apache-maven-3.6.3-bin.tar.gz -C /tmp
      mv /tmp/apache-maven-3.6.3 /usr/local
      ln -s /usr/local/apache-maven-3.6.3/bin/mvn /usr/bin/mvn
    sudo: yes
    when: mvn_is_installed.stat.exists == False
  - name: Check if Spark is installed
    stat:
      path: /opt/spark-2.4.0-bin-hadoop2.7/bin/spark-shell
    register: spark_is_installed
  - name: Install Spark
    shell: |
      wget -P /tmp https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz
      tar -zxf /tmp/spark-2.4.0-bin-hadoop2.7.tgz -C /tmp
      mv /tmp/spark-2.4.0-bin-hadoop2.7 /opt
      ln -s /opt/spark-2.4.0-bin-hadoop2.7 /opt/spark
    sudo: yes
    when: spark_is_installed.stat.exists == False
  - name: Check if Anaconda is installed
    stat:
      path: /usr/local/anaconda3/bin/python
    register: anaconda_is_installed
  - name: Install Packages for Anaconda
    apt:
      name: "{{ packages }}"
    vars:
      packages:
      - bzip2
  - name: Install Anaconda
    shell: |
      wget -P /tmp https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh
      bash /tmp/Anaconda3-2019.10-Linux-x86_64.sh -b -p /usr/local/anaconda3
      chown -R ubuntu:ubuntu /usr/local/anaconda3
    sudo: yes
    when: anaconda_is_installed.stat.exists == False
  - name: Ansible Insert multiple lines using blockinfile
    blockinfile:
      dest: /etc/bash.bashrc
      block: |
        export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
        export PATH=$PATH:$JAVA_HOME/bin
        export SCALA_HOME=/usr/share/scala
        export PATH=$PATH:$SCALA_HOME/bin
        export MAVEN_OPTS="-Xmx2g -XX:ReservedCodeCacheSize=512m"
        export M2_HOME=/usr/local/apache-maven-3.6.3
        export SPARK_HOME=/opt/spark-2.4.0-bin-hadoop2.7
        export PYTHONPATH=$SPARK_HOME/python/:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip
        export PATH="/usr/local/anaconda3/bin:$PATH"
        export SPARK_LOCAL_IP='127.0.0.1'
      backup: yes
#  - name: Install Jupyter with pip
#    shell: |
#      pip install jupyter
#    sudo: yes
  - name: Install Docker Apt Prerequisites
    apt:
      name: "{{ packages }}"
      install_recommends: no
    vars:
      packages:
      - apt-transport-https
      - ca-certificates
      - curl
      - software-properties-common
  - name: Install more Docker Prereqs
    shell: |
      curl -fsSL https://apt.dockerproject.org/gpg | apt-key add -
      apt-key fingerprint 58118E89F3A912897C070ADBF76221572C52609D
      add-apt-repository "deb https://apt.dockerproject.org/repo/ ubuntu-$(lsb_release -cs) main"
    sudo: yes
  - name: Install Docker
    apt:
      name: "{{ packages }}"
      update_cache: yes
    vars:
      packages:
      - docker-engine
  - name: Docker Hello World as root
    shell: |
      docker run hello-world
    sudo: yes
  - name: Add Docker Rights to Ubuntu User
    shell: |
      usermod -aG docker ubuntu
    sudo: yes
  - name: Docker Hello World as ubuntu user
    shell: |
      docker run hello-world
#    become: yes
#    become_user: ubuntu
  - name: Check SBT Installed
    shell: dpkg --status sbt | grep 'install ok installed'
    register: sbt_is_installed
    failed_when: no
    changed_when: no
  - name: Install SBT
    shell: |
      wget -O /tmp/sbt-1.3.7.deb "https://bintray.com/sbt/debian/download_file?file_path=sbt-1.3.7.deb"
      dpkg -i /tmp/sbt-1.3.7.deb
    when: sbt_is_installed.rc == 1
    sudo: yes
  - name: Install make for Toree
    apt:
      name: "{{ packages }}"
    vars:
      packages:
      - make
  - name: Check if Toree Pip File is Installed
    stat:
#      path: /usr/local/lib/python2.7/dist-packages/toree/lib/toree-assembly-0.3.0-incubating.jar
      path: /usr/local/anaconda3/lib/python3.7/site-packages/toree/lib/toree-assembly-0.3.0-incubating.jar
    register: toree_is_installed
#  - name: Docker Hello World as ubuntu user
#    shell: |
#      docker run hello-world
#    become: yes
#    become_user: ubuntu
#  - name: Install Toree
#    shell: |
#      pip install toree==0.3.0
#    become: yes
#    become_user: ubuntu
#    when: toree_is_installed.stat.exists == False
#  - name: Install Toree
#    shell: |
#      jupyter toree install --spark_opts='--master=local[1]' --spark_home=/opt/spark-2.4.0-bin-hadoop2.7
#    sudo: yes
#    when: toree_is_installed.stat.exists == False
##      wget -P /tmp https://github.com/apache/incubator-toree/archive/v0.3.0-incubating-rc1.tar.gz 
##      tar -zxf /tmp/v0.3.0-incubating-rc1.tar.gz -C /tmp
##      bash -lc "cd /tmp/incubator-toree-0.3.0-incubating-rc1 && git init"
##      bash -lc "cd /tmp/incubator-toree-0.3.0-incubating-rc1 && make release"
##      bash -lc "cd /tmp/incubator-toree-0.3.0-incubating-rc1 && make release"
##      bash -lc "cd /tmp/incubator-toree-0.3.0-incubating-rc1 && make release"
##      pip install toree --no-index --find-links file:///tmp/incubator-toree-0.3.0-incubating-rc1/dist/toree-pip/toree-0.3.0.tar.gz
##    sudo: yes
#  - name: Copy Spark Env File
#    shell: |
#      cp /opt/spark-2.4.0-bin-hadoop2.7/conf/spark-env.sh.template /opt/spark-2.4.0-bin-hadoop2.7/conf/spark-env.sh
#  - name: Write Environment Variables in spark-env.sh
#    blockinfile:
#      dest: /opt/spark-2.4.0-bin-hadoop2.7/conf/spark-env.sh
#      block: |
#        export  SPARK_MASTER_HOME=127.0.0.1
#        export  SPARK_MASTER_IP=127.0.0.1
#        export  SPARK_LOCAL_IP=127.0.0.1
#      backup: yes
#  - name: Remove Blank Toree Spark Options
#    lineinfile:
#      dest: /usr/local/share/jupyter/kernels/apache_toree_scala/kernel.json
#      regexp: '^.*TOREE_SPARK_OPTS'
#      state: absent
#  - name: Update Toree Spark Options
#    blockinfile:
#      dest: /usr/local/share/jupyter/kernels/apache_toree_scala/kernel.json
#      block: |
#         "__TOREE_SPARK_OPTS__": "--master=local[1]",
#      backup: yes
#      insertafter: ^.*env
#      state: present
#  - name: Create Jupyter Script
#    shell: |
#      echo "jupyter notebook --ip=* --no-browser &" > /home/ubuntu/jup.sh
#      chmod a+x /home/ubuntu/jup.sh
